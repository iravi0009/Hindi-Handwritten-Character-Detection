{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "324f5ce4-ed21-49b0-a9f4-9ff6f20ef3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.optimizers import schedules, Adam\n",
    "from tensorflow.keras import callbacks\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99af2fbb-86d7-4ce2-b64e-ccb7cd94b853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories\n",
    "train_dir = \"C:/Users/Mahendra/Downloads/htr research paper/DevanagariHandwrittenCharacterDataset/Train\"\n",
    "test_dir = \"C:/Users/Mahendra/Downloads/htr research paper/DevanagariHandwrittenCharacterDataset/Test\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7677371-9830-41bb-a5e0-b0688432f2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "img_height = 64\n",
    "img_width = 64\n",
    "batch_size = 32\n",
    "num_classes = 46  # Assuming 46 classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e611ff1-31bc-49a4-8231-b739c2dac189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    layers.RandomRotation(0.2),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ca0fafc-d3cd-4239-8223-71a6c629561f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 78200 files belonging to 46 classes.\n",
      "Using 62560 files for training.\n"
     ]
    }
   ],
   "source": [
    "# Create training and validation datasets with data augmentation\n",
    "train_ds = image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    seed=123,\n",
    "    label_mode=\"categorical\",\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69da13b9-598b-4c70-928d-ad07375bd69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 78200 files belonging to 46 classes.\n",
      "Using 15640 files for validation.\n"
     ]
    }
   ],
   "source": [
    "val_ds = image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    validation_split=0.2,\n",
    "    subset='validation',\n",
    "    seed=123,\n",
    "    label_mode=\"categorical\",\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67bdd4ce-368a-4f92-bd8f-84b0307c379e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13800 files belonging to 46 classes.\n"
     ]
    }
   ],
   "source": [
    "# Test dataset\n",
    "test_ds = image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    seed=123,\n",
    "    label_mode=\"categorical\",\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e67604bb-18d7-441b-a90b-3169ae42af62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUTOTUNE optimizes dataset loading\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7296a46f-d9af-48f9-96f6-a066b91be4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    data_augmentation,  # Apply data augmentation\n",
    "    \n",
    "    # Convolutional Layer 1\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.SeparableConv2D(64, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    # Convolutional Layer 2\n",
    "    layers.SeparableConv2D(128, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    # Convolutional Layer 3\n",
    "    layers.SeparableConv2D(256, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.GlobalAveragePooling2D(),  # Using Global Average Pooling instead of flattening\n",
    "\n",
    "    # Dense Layers with Dropout\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    layers.Dropout(0.5),\n",
    "    \n",
    "    layers.Dense(num_classes, activation='softmax')  # Output layer\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07ae2770-ee4a-498b-a55b-ff256095235c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with Adam optimizer and learning rate scheduler\n",
    "initial_learning_rate = 1e-3\n",
    "lr_schedule = schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True)\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=lr_schedule),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7235d0fd-4245-446c-80de-ae9a6c977202",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = callbacks.EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bcec90f-f85d-48cd-a5a0-aabbea4d9c16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential (Sequential)     (32, 64, 64, 3)           0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (32, 62, 62, 32)          896       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (32, 62, 62, 32)         128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " separable_conv2d (Separable  (32, 60, 60, 64)         2400      \n",
      " Conv2D)                                                         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (32, 60, 60, 64)         256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (32, 30, 30, 64)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " separable_conv2d_1 (Separab  (32, 28, 28, 128)        8896      \n",
      " leConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (32, 28, 28, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (32, 14, 14, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " separable_conv2d_2 (Separab  (32, 12, 12, 256)        34176     \n",
      " leConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (32, 12, 12, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (32, 256)                0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (32, 256)                 65792     \n",
      "                                                                 \n",
      " dropout (Dropout)           (32, 256)                 0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (32, 46)                  11822     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 125,902\n",
      "Trainable params: 124,942\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_ds.take(1):  # Take one batch from training data\n",
    "    model(images)  # This \"calls\" the model with data and builds it\n",
    "\n",
    "model.summary()  # Now the model is built, and you can print the summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a6b6a5-19d7-45de-8019-5c6c86768e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      " 248/1955 [==>...........................] - ETA: 16:13 - loss: 3.7256 - accuracy: 0.0878"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=15,\n",
    "    callbacks=[early_stopping]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f065b695-ef4f-42bd-807f-f1291ba1dc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_ds)\n",
    "print(f\"Test accuracy: {test_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5f7beb-58e9-4cec-83dc-688302868201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Accuracy and Loss\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(1, len(acc) + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd214ea-0838-4f36-acf5-7fe800b233a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafb4fcd-bce4-43de-a5a8-21a23adf5b1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
